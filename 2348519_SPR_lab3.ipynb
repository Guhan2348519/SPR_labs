{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTWJqYWofr0x/phEHTufIr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guhan2348519/SPR_labs/blob/main/2348519_SPR_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Record audio using PyAudio\n",
        "def record_audio(filename=\"output.wav\", duration=5):\n",
        "    CHUNK = 1024\n",
        "    FORMAT = pyaudio.paInt16\n",
        "    CHANNELS = 1\n",
        "    RATE = 16000\n",
        "    RECORD_SECONDS = duration\n",
        "    WAVE_OUTPUT_FILENAME = filename\n",
        "\n",
        "    p = pyaudio.PyAudio()\n",
        "\n",
        "    stream = p.open(format=FORMAT,\n",
        "                    channels=CHANNELS,\n",
        "                    rate=RATE,\n",
        "                    input=True,\n",
        "                    frames_per_buffer=CHUNK)\n",
        "\n",
        "    print(\"Speak something...\")  # Prompt the user to start speaking\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "        data = stream.read(CHUNK)\n",
        "        frames.append(data)\n",
        "\n",
        "    print(\"Recording finished.\")  # Inform the user recording has ended\n",
        "\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()\n",
        "\n",
        "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
        "    wf.setnchannels(CHANNELS)\n",
        "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
        "    wf.setframerate(RATE)\n",
        "    wf.writeframes(b''.join(frames))\n",
        "    wf.close()"
      ],
      "metadata": {
        "id": "oGM9ttsegUoL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess audio using Librosa (extract MFCC features)\n",
        "def preprocess_audio(filename):\n",
        "    print(\"Recognizing...\")  # Indicate that recognition is in progress\n",
        "    try:\n",
        "        audio, sr = librosa.load(filename, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "\n",
        "        # Visualize MFCCs\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "        plt.colorbar()\n",
        "        plt.title('MFCC')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return mfccs\n",
        "    except Exception as e:\n",
        "        print(\"Error during recognition:\", str(e))\n",
        "        return None"
      ],
      "metadata": {
        "id": "AyYdp50IgoZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tkinter import Tk, filedialog"
      ],
      "metadata": {
        "id": "nCNtaCznhZ2S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Recognize speech using a pre-trained KNN model\n",
        "def recognize_speech(mfccs, knn):\n",
        "    try:\n",
        "        # Predict the speech-to-text conversion from the MFCCs\n",
        "        predicted_text = knn.predict([mfccs.mean(axis=1)])  # Example prediction logic\n",
        "        print(f\"Speech recognized: '{predicted_text[0]}'\")\n",
        "        print(\"Speech successfully converted to text!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in recognizing speech: {e}\")\n",
        "        print(\"Speech Recognition could not understand audio. Please try speaking more clearly.\")"
      ],
      "metadata": {
        "id": "ivm038zlg_O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    # Simulating the training process\n",
        "    X = np.random.rand(100, 13)  # Example MFCC features\n",
        "    y = np.array([\"hello\", \"lights\", \"off\", \"on\"] * 25)  # Example labels\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Training complete. Model accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    return knn"
      ],
      "metadata": {
        "id": "qPVzFSiYhEnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to upload an audio file\n",
        "def upload_audio_file():\n",
        "    root = Tk()\n",
        "    root.withdraw()  # Hide the main window\n",
        "    filename = filedialog.askopenfilename(title=\"Select an Audio File\", filetypes=[(\"Audio Files\", \"*.wav *.mp3\")])\n",
        "    return filename\n",
        "\n",
        "def main():\n",
        "    # Train the model (for demonstration purposes)\n",
        "    knn = train_model()\n",
        "\n",
        "    # Provide user with two options\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Record speech using microphone\")\n",
        "    print(\"2. Upload an audio file\")\n",
        "\n",
        "    choice = input(\"Enter 1 or 2: \")\n",
        "\n",
        "    if choice == '1':\n",
        "        # Record audio via microphone\n",
        "        record_audio()\n",
        "        filename = \"output.wav\"  # Recorded audio will be saved as output.wav\n",
        "    elif choice == '2':\n",
        "        # Upload audio file\n",
        "        filename = upload_audio_file()\n",
        "        if not filename:\n",
        "            print(\"No file selected. Exiting.\")\n",
        "            return\n",
        "    else:\n",
        "        print(\"Invalid choice. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Preprocess audio and extract MFCCs\n",
        "    mfccs = preprocess_audio(filename)\n",
        "\n",
        "    # Recognize speech based on MFCCs\n",
        "    if mfccs is not None:\n",
        "        recognize_speech(mfccs, knn)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "j5y8i1dzhKjZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}